音视频

janus server：开源服务通话

webrtc：web端的实时通讯

使用的协议

![image-20230514152205252](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514152205252.png)

daemon的使用介绍

"Daemon"（守护进程）是在后台运行的计算机程序，通常在操作系统启动时自动启动。它们通常不与用户交互，而是在后台执行各种系统任务，例如监控硬件、网络等，保持系统运行稳定并且可靠。

在Unix和Linux系统中，一些常见的守护进程包括cron（用于定期执行任务）、sshd（用于远程登录）、httpd（用于Web服务器）等。

要创建一个守护进程，需要使用类似于以下步骤的方法：

1. 调用fork()函数来创建一个新进程。
2. 在子进程中调用setsid()函数以脱离控制终端。
3. 关闭所有文件描述符（或将其重定向到/dev/null）以避免意外输出到控制台。
4. 在后台中执行所需的任务，并处理任何错误。



RTP：协议传输视频或者音频，环形队列通过传输时间决定大小，通过队列组成帧推出解码使用

![image-20230514153326527](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514153326527.png)

利用时间搓来进行数据的合并保存

发送的ssrc，混音的csrc共享源。

连通率：tcp进行连通率

RTCP协议：headr填充位

![image-20230514154458104](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514154458104.png)

RTCP type：sr，rr关键判断报文

![image-20230514154742534](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514154742534.png)

![image-20230514155044389](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514155044389.png)

stun协议：进行nat穿越，将外网ip带入，且传入外网

ice工作原理：一个地址包含4元组 协议 ip 类型和端口

![image-20230514155907527](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514155907527.png)

DTLS协议：

媒体协商:

SDP协议使用：

mesh架构：

![image-20230514160918114](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230514160918114.png)

webrtc：api接口

![image-20230515144445077](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515144445077.png)

![image-20230515144526627](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515144526627.png)

# rtcpeerconnaction

RTCPeerConnection 是 WebRTC 标准中的一个关键接口，用于在浏览器之间建立点对点（P2P）的实时音视频通信。以下是使用 RTCPeerConnection 进行音视频通话的示例：

1. 创建 RTCPeerConnection 对象：在 JavaScript 中创建 RTCPeerConnection 对象，并设置其相关属性和事件处理函数。例如，设置 ICE 服务器列表、SDP 协商流程、错误处理等。

```
Codevar pc = new RTCPeerConnection({
    iceServers: [
        {urls: 'stun:stun.l.google.com:19302'},
        {urls: 'turn:numb.viagenie.ca', credential: 'xxxxxx', username: 'yyyyyy'}
    ]
});

pc.onicecandidate = function(event) {
    if (event.candidate) {
        // 发送本地 ICE 候选项给远端
    }
};

pc.onnegotiationneeded = function() {
    // 发起 SDP 协商过程
};

pc.ontrack = function(event) {
    // 处理接收到的媒体流
};
```

1. 创建本地媒体流：使用 WebRTC 的 getUserMedia() 方法，从本地摄像头和麦克风中捕获音视频数据，并将其封装成 MediaStream 对象。

```javascript
 Codenavigator.mediaDevices.getUserMedia({video: true, audio: true})
    .then(function(stream) {
        // 将本地媒体流添加到 RTCPeerConnection 对象中
        stream.getTracks().forEach(function(track) {
            pc.addTrack(track, stream);
        });
    })
    .catch(function(error) {
        console.log('getUserMedia() error: ' + error.message);
    });
```

1. 与远端建立连接：通过 RTCPeerConnection 对象的 createOffer() 方法，生成本地 SDP 描述符，并将其发送给远端浏览器。远端浏览器收到 SDP 描述符后，通过 createAnswer() 方法生成自己的 SDP 描述符，并将其发送回来。

```
Copy Codepc.createOffer({
    offerToReceiveVideo: true,
    offerToReceiveAudio: true
})
.then(function(offer) {
    return pc.setLocalDescription(offer);
})
.then(function() {
    // 将本地 SDP 描述符发送给远端
})
.catch(function(error) {
    console.log('createOffer() error: ' + error.message);
});
```

1. 完成媒体流交换：当双方都收到了对方的 SDP 描述符，并通过 setRemoteDescription() 方法进行了设置后，SDP 协商过程完成，双方之间建立的媒体流通道即可正常工作。

```
Copy Codepc.setRemoteDescription(answer)
.then(function() {
    console.log('Remote description set successfully');
})
.catch(function(error) {
    console.log('setRemoteDescription() error: ' + error.message);
});

pc.setLocalDescription(offer)
.then(function() {
    console.log('Local description set successfully');
})
.catch(function(error) {
    console.log('setLocalDescription() error: ' + error.message);
});
```

综上所述，使用 RTCPeerConnection 接口可以在浏览器之间实现点对点的音视频通信，通过 ICE 服务器、SDP 描述符等技术手段实现 NAT 穿透和流媒体数据的传输。在这个过程中，需要处理 ICE 候选项、SDP 协商、媒体流的加入和退出等问题，以保障通信的质量和稳定性。

直播使用Rtmp：多级使用，单向传播

cdn带宽

webrtc：双向传播，单人

通话原理：
1.媒体协商

![image-20230515145238190](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515145238190.png)

A端发送vp8做编码，那么B端如何解码,用H264解码

B端发送vp8做编码，那么A端如何解码

交换sdp信息

2.网络协商（sdp）

获取外网ip，利用信令服务器

NAT：路由器有的外网ip，端口映射，stun获取映射自己的公网地址

turn：外网映射不通，添加relay中继服务进行数据转发，带宽大单向200kbs：

![image-20230515151126871](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515151126871.png)

candidate网络协商

信令服务器：signal server，交互sdp和candidate

房间号：管理正确通信

人员进出:

webRTC API：

mediastream表示媒体流数据，利用getUserMedia接口获取，

RTCPeerConnaction:对象允许用户在两个浏览器直接通信

![image-20230515151948213](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515151948213.png)

![image-20230515152231291](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515152231291.png)

# ice server：



利用coturn:进行turn和stun打洞使用中继或者p2p

浏览器获取摄像头和麦克风：

![image-20230515154846189](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515154846189.png)

```
video
```

websocket：

![image-20230515160550852](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515160550852.png)

![image-20230515161036571](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20230515161036571.png)

信令协议设计：

利用join,new-peer,

通过在一个房间加入两个通话。

configuration:

```

```

web在js中实现api接口的调用。

## 音视频基础

### 视频播放原理

![image-20240301234056520](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240301234056520.png)

```
媒体文件-》解复用器
audio线程
video线程处理
采样是pcm的音频
yuv的视频，然后渲染处理同步输出
foramat流数据streams：音频，视频，字幕
视频->medimutex->packet->code->farme
```

#### 流媒体软解

```
获取流媒体数据：从网络或本地文件中获取流媒体数据，这些数据可能以特定的封装格式（如 MP4、FLV、HLS 等）进行了编码。
解析封装格式：使用相应的解析器（如 FFmpeg、GStreamer 等）解析封装格式，提取出音频和视频的数据流。
解码音视频数据：使用解码器（如 FFmpeg 的 libavcodec 库）对音频和视频数据进行解码，将其转换为原始的音频样本和视频帧。
音视频同步：根据音频和视频的时间戳信息，进行音视频同步操作，确保音频和视频在播放时保持同步。
播放音视频：将解码后的音频样本和视频帧交给音频和视频播放器进行实际的播放操作。
```

### 视频文件的构成

```
视频码率bitrate：
kb/s视频质量视频码率越高，每秒传输的数据量就越大，视频的清晰度也会更高。然而，高码率也会导致文件大小增加，传输所需的带宽要求也更高。
视频帧率：fps
流畅度  问题是否跟播放速度有：
如果视频帧率高于播放速度，播放器可能会丢弃部分帧来适应播放速度，导致画面不够流畅，甚至出现跳帧的情况。
如果视频帧率低于播放速度，播放器可能会使用重复帧或插入新帧的方式来填补缺失的帧，以保持播放速度，并且可能导致画面看起来比较卡顿。

视频分辨率：视频图像大小
4k,2k是否受显示器的影响？
是的，4K 和 2K 分辨率受到显示器的影响。显示器的分辨率决定了它能够显示的像素数量，从而影响了视频、图像和文本在屏幕上的清晰度和细节展示。

4K 分辨率通常指3840x2160像素，也被称为Ultra HD。这种高分辨率提供了更多的像素，使得图像更加清晰、细节更加丰富，适合大屏幕显示器或电视。

2K 分辨率一般指2560x1440像素，也被称为Quad HD。虽然比1080p高出一些像素，但相比4K分辨率来说显示效果稍显逊色，但仍然提供比较清晰的图像和文本显示。

```

### IPB帧的概率

```
I帧不需要其他的画面参考，在frame->frametype(KRY_FRAME)
直接成像
P帧向前预测的帧间，图片
B帧：双向事件预测

```

### 音频基础

#### 声音的参数

```
采样帧率：44100 播放速度有关
越高声音越来，波峰越高，声音越尖锐
声调，变速不变调
采样深度 16bit

通道数 2
音频LRLR格式的采样数
LLLRRRR格式的采样数
音频时间=采样帧数/采样帧率
```

###### DirectShow

#### 音视频时间戳

```
https://blog.csdn.net/xipiaoyouzi/article/details/90479294
```



### ffmepg

![image-20240303015643387](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303015643387.png)

![image-20240303015709554](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303015709554.png)

```
流程：读文件->解封装-解码->转换参数
新编码->封装->写如文件
ffmpeg 首先读取输入源；然后通过 Demuxer
音视频包进行解封装， li bavformat 中的接口即可实现；接下来通过
Decoder 进行解码，将音视频通过 Decoder 解包成为 YVU 或者 PCM 这样的数据， Decoder
通过 libavcodec 中的接口即可实现；然后通过 Enco der 将对应的数据进行编码，编码可以
通过 libavcodec 中的接口来实现；接下来将编码后的音视频数据包通过 uxer 进行封装，
Muxer 封装通过 ibavformat 中的接口即可实现，输出成为输出流


```

#### 支持的编码器

```
如 AAC AC3,
H.264 H.265 PEG4 MPEG2VIDEO PCM FLVl 的编码器支持
AAC (Advanced Audio Coding):

AAC 是一种广泛使用的音频编码格式，通常用于存储和传输音乐和其他类型的音频。
举例：在 iTunes Store 中，音乐文件通常以 AAC 格式进行编码。
AC3 (Dolby Digital):

AC3 是杜比数字音频编码的一种格式，通常用于 DVD、蓝光碟和数字电视等媒体中。
举例：在 DVD 视频中，常见的音频轨道格式之一就是 AC3。
H.264 (Advanced Video Coding):

H.264 是一种高效的视频压缩标准，具有出色的视频质量和较低的比特率。
举例：大多数在线视频平台（如 YouTube、Netflix）都使用 H.264 来存储和传输视频内容。
H.265 (High Efficiency Video Coding, HEVC):

H.265 是 H.264 的后继者，具有更高的压缩效率和更好的视频质量，适合高清和超高清视频。
举例：4K 蓝光碟通常采用 H.265 编码来支持高分辨率视频内容。
MPEG4 (Moving Picture Experts Group-4):

MPEG4 是一种多媒体压缩标准，支持音频、视频和交互式多媒体内容。
举例：在网络视频流媒体中，许多视频文件都使用 MPEG4 编码格式。
MPEG2VIDEO:

MPEG2VIDEO 是 MPEG-2 标准定义的视频编码格式，适用于数字电视、DVD 和一些广播应用。
举例：DVD 视频通常采用 MPEG2VIDEO 编码格式。
PCM (Pulse Code Modulation):

PCM 是一种无损音频编码格式，广泛用于存储和处理未经压缩的音频数据。
举例：音频 CD 将音频以 PCM 格式进行存储和传输。
FLV (Flash Video):

FLV 是 Adobe Flash Player 支持的一种视频容器格式，常用于网络视频流媒体。
举例：以前的 YouTube 视频通常以 FLV 格式进行存储和传输。
```

#### 通信协议支持

```
FFmpeg 支持的流媒体协议比较多，包括 MMS,
HTTP HTTPS HLS(M3U8) RTMP RTP ，甚至支持 TCP UDP 
MMS (Microsoft Media Server):

MMS 是微软开发的流媒体传输协议，用于在 Windows 平台上传输音视频流。
举例：以前的一些 Windows 媒体播放器使用 MMS 协议来播放在线流媒体内容。
HTTP 和 HTTPS:

HTTP 和 HTTPS 是标准的超文本传输协议，用于在 Web 上传输各种数据，包括音视频流。
举例：许多在线视频平台（如 YouTube、Vimeo）通过 HTTP 或 HTTPS 协议进行视频流的传输和分发。
HLS (HTTP Live Streaming, M3U8):

HLS 是由苹果公司提出的流媒体传输协议，适用于移动设备和桌面浏览器。
举例：许多移动应用和网页使用 HLS 协议来实现音视频流的直播和点播功能。
RTMP (Real-Time Messaging Protocol):

RTMP 是 Adobe 开发的用于实时音视频通信的协议，常用于直播和互动式多媒体应用。
举例：许多直播平台（如 Twitch、Facebook Live）使用 RTMP 协议进行实时视频流的传输。
RTP (Real-time Transport Protocol) 和 RTSP (Real Time Streaming Protocol):

RTP 和 RTSP 是用于实时音视频数据传输和控制的标准协议，广泛用于 IP 网络中的流媒体传输。
举例：许多视频会议系统和监控摄像头都使用 RTP 和 RTSP 协议进行音视频数据的传输和控制。
TCP 和 UDP:

TCP 和 UDP 是两种基本的传输层协议，FFmpeg 支持将音视频流通过 TCP 或 UDP 进行传输。
举例：在实时视频会议或监控系统中，可以使用 TCP 或 UDP 协议传输音视频数据。
```



#### swscal图像转换计算模块

```
图像转换yuv，RGB，1080p
```

#### swersample音频转换模块

```
采样率（Sampling Rate）：

采样率指每秒钟对声音信号的采样次数，用赫兹（Hz）来表示。
例如，采样率为 48000Hz 表示每秒对声音信号进行了 48000 次采样。
高采样率可以更准确地表示原始声音信号，因此能够获得更高质量的音频。
采样格式（Sampling Format）：

采样格式表示在进行数字化采样时，每个采样点所占用的位数以及编码方式。
例如，f32le 表示每个采样点使用 32 位浮点数进行存储。
不同的采样格式会对音频的动态范围、信噪比等方面产生影响。
声道数（Number of Channels）：

声道数表示音频信号中独立的声道数量，通常用数字来表示（如 1 表示单声道，2 表示立体声）。
例如，单声道表示只有一个声道，而立体声表示左右两个独立的声道。
声道数影响了音频的空间表现和立体感，不同的声道数会带来不同的听觉体验。
```



### ffplay

```


```



### ffprobe流媒体信息获取

```

```

### 转码格式

#### MP4

```
式标准为 IS0-14496 Part 12，
```

####  MP4 的必要格式

```
BOX：header和Data
fullbox：+version24
必要 Box：

ftyp（File Type Box）：描述文件类型和版本信息。
moov（Movie Box）：包含了媒体文件的整体结构信息。
mdat（Media Data Box）：存储实际的媒体数据。
mvhd（Movie Header Box）：包含了关于整个电影的信息，如时长、时间刻度等。
trak（Track Box）：描述单个媒体轨道的信息。
tkhd（Track Header Box）：包含有关媒体轨道的信息，如轨道类型、时长等。
mdia（Media Box）：包含了媒体数据的详细描述。
mdhd（Media Header Box）：提供有关媒体数据的信息，如时间刻度、语言等。
hdlr（Handler Reference Box）：指示媒体处理程序的类型。
minf（Media Information Box）：提供了关于媒体数据的信息。
可选 Box：

udta（User Data Box）：存储用户自定义的元数据信息。
stbl（Sample Table Box）：包含了媒体样本的时间偏移、大小、编解码信息等。
meta（Meta Box）：包含了元数据信息，如标题、艺术家等。
dinf（Data Information Box）：提供了媒体数据存储的位置信息。
stts（Time-to-Sample Box）：描述了媒体样本的时间戳和持续时间。
stsc（Sample-to-Chunk Box）：定义了样本在 chunk 中的映射关系。
stsd（Sample Description Box）：包含了媒体样本的编解码器信息。
stsz（Sample Size Box）：指示每个样本的大小。
stco（Chunk Offset Box）：定义了每个 chunk 在文件中的偏移量。
ctts（Composition Time-to-Sample Box）：描述了媒体样本的合成时间与显示时间的偏移。
```

##### moov容器数据信息

![image-20240229221706085](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240229221706085.png)

```
容器是atom，一下三种的atom的一种
mvhd（Movie Header atom）：mvhd Box 未压缩的影片头信息，如时长、时间刻度、音频/视频轨道数等。

cmov（Compressed Movie atom）：用于指示文件中的数据已经被压缩。在某些情况下，视频文件可能会被压缩以节省空间，

rmra：参考电影信息容器
```

![image-20240301002205974](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240301002205974.png)

### MP4分析工具

```
1. Elecard StreamEye
2.mp4box
3.mp4info
```

#### MP4 FFmpeg 中的 Demuxer

```
1.Demuxer指负责将多媒体文件解复用（demultiplexing）为音频流、视频流等元素流的组件。Demuxer 的作用是从输入的多媒体文件中提取出各种流（如音频流、视频流、字幕流等），并将这些不同类型的流分离出来，以便后续进行解码、处理和展示。
2.Muxer 是指负责将音频流、视频流等元素流混合（multiplexing）为一个容器格式的组件。Muxer 的作用是将各种类型的媒体流（如音频流、视频流、字幕流等）封装成特定的容器格式（如 MP4、FLV、MKV 等），以便于存储、传输和播放。
 use_absolute_path <boolean>
 seek_streams_individually <boolean>   
 ignore_editlist  
 advanced_editlist 
 ignore_chapters
 
enable_drefs   
 外部 track 支持，默认不开启
```

#####  use_absolute_path :bool

```
可以通过绝对路径加载外部的 track ，可能会有安全因素的影响，默认不开启
```

##### seek_streams_individually :bool

```
根据单独流进行 seek ，默认开启
```

##### EditList Atom 

```
是 MP4 文件中的一个原子（Atom），用于描述对媒体时间轴进行编辑的信息。它包含了一系列编辑条目，每个编辑条目描述了一个时间范围的偏移量和时长，用于指示在播放该媒体时需要如何进行时间轴的编辑。
具体来说，EditList Atom 包含了以下信息：

媒体时间轴中需要进行编辑的时间范围；
每个时间范围的偏移量（即开始时间）和时长（持续时间）；
编辑操作类型，如剪切、拼接等。
通过解析 EditList Atom，可以实现对媒体时间轴的编辑控制，从而实现视频剪辑、视频拼接等功能。

下面是一个简单的示例 C++ 代码，演示如何使用 FFmpeg 解析 MP4 文件中的 EditList Atom，并获取其中的编辑信息：

cpp
extern "C" {
#include <libavformat/avformat.h>
}

int main() {
    av_register_all();

    AVFormatContext *formatContext = avformat_alloc_context();
    if (avformat_open_input(&formatContext, "input.mp4", nullptr, nullptr) != 0) {
        // 打开文件失败
        return -1;
    }

    if (avformat_find_stream_info(formatContext, nullptr) < 0) {
        // 获取流信息失败
        return -1;
    }

    AVDictionaryEntry *entry = nullptr;
    while ((entry = av_dict_get(formatContext->metadata, "", entry, AV_DICT_IGNORE_SUFFIX))) {
        if (strcmp(entry->key, "editlist") == 0) {
            // 获取 EditList Atom 的信息
            const char *editListInfo = entry->value;
            // 解析并处理 EditList Atom 的信息
            // 可以根据具体需求自行编写解析逻辑
        }
    }

    avformat_close_input(&formatContext);
    avformat_free_context(formatContext);

    return 0;
}
```

#### MP4 FFmpeg 中的 muxer

![image-20240301005106597](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240301005106597.png)

![image-20240302211050799](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302211050799.png)

```
movflags
moov_size
rtpflags
skip_iods

```

##### .faststart 参数使用案例

```
正常情况下 ffmpeg 生成 moov 是在 dat 写完成之后再写入，可以通过参数 fasts tart
moov 容器移动至 mdat 的前面，
ffmpeg -i input.flv -c copy -f mp4 -movflags faststart output.mp4
```

#### dash参数使用案例

```
./ffmpeg -i input.flv -c copy -f mp4 -movflags dash output.mp4 
主要使用容器：sidx，moof，mdat
```

##### isml参数使用案例

```
./ffmpeg -re -i input.mp4 -c copy -movflags isml+frag_keyframe -f ismv Stream 
直播流ismv推流到iis服务器
```

### 视频转FLV文件格式

![image-20240302213122855](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213122855.png)

```
直播使用

```

#### FLV文件头格式

![image-20240302211834733](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302211834733.png)

```

```

#### FLV 文件 TAG 排列方式

![image-20240302213143852](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213143852.png)

```
preytagsize0
TAG2
...
```

#### FLVTAG格式解释

![image-20240302212808836](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302212808836.png)

##### FLVTAG Header 

```
FLVTAG Header 部分信息如下
．保留位占用 位，最大为 lb
·滤镜位占用 位，最大为 lb
•TAG 类型占用 位；最大为 lllllb ，与保留位 滤镜位共用 个字节，常见的为Ox08 Ox09 Ox12 ；在处理时， 一般默认将保留位与滤镜位设置为

·数据大小占用 24 位（ 字节），最大为 OxFFFFFF ( 16 777 215 ）宇节

·时间戳大小占用 24 位（ 字节 ，最大为 OxFFFFFF ( 16 777 215 ）毫秒，转换为秒等于 16 777 秒，转换为分钟为 279 分钟，转换为小时为 .66 小时，所以如果使用FLv的格式，采用这个时间戳最大可以存储至 4.66 小时
·扩展时间戳大小占用 位（ 字节），最大为 OxFF ( 255 ），扩展时间戳使得 FLY
有的时间戳得到了扩展，不仅仅局限于 4.66 个小时，还可以存储得更久， 1193小时，以天为单位转换过来大约为 49.7

·流 ID 占用 24 位（ 字节），最大为 OxFFFFFF ；不过 FLY 中一直将其存储为
紧接着在 FLVTAG header 之后存储的数据为 TAG data ，大小为 FLVTAG
Header DataSize 中存储的大小，存储的数据分为视频数据、音频数据及脚本数据
```

##### TAG data 数据

```
videoTag 数据解析：TAG 类型占用Ox09
 AudioTag 数据格式解析:TAG 类型占用Ox08
 scriptData 格式解析:TAG 类型占用Ox012
```

###### videoTag 数据解析

![image-20240302213421047](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213421047.png)![image-20240302213430890](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213430890.png)

```

```

######  AudioTag 数据格式解析

**![image-20240302213714447](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213714447.png)**

![image-20240302213726629](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213726629.png)

```

```

###### scriptData 格式解析

![image-20240302213805079](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302213805079.png)

```

```

#### FFmpeg转FLV参数

**![image-20240302214124770](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302214124770.png)**

```
需要aac_seq_header_detect

```

#### FLVf封装支持的编码

```
FLV 封装中支持的视频主要包含如下内容
• Sorenson H.263
• Screen Video
• On2 VP6
·带 Alpha 通道的 On2 VP6
• Screen Video 2
• H.264 (AVC)
FLV 封装中支持的音频主要包含如下内容
．限行 PCM ，大小端取决于平台
• ADPCM 音频格式
• MP3
·线性 PCM ，小端
• Nellymoser 16kHz Mono
• Nellymoser 8kHz Mono
• N ellymoser 
• G.711 A-law
• G.711 mu-law
• AAC
• Speex
• MP3 8kHz
```

#### FLV封装不支持的编码举例

```
ffmpeg -i input ac3.mp4 -c copy -f flv output.flv
使用ac3编码出现错误
如果音频使用的是ac3可以转为acc
，可以进行转码，将音频从 AC3 转换为 AAC 或者 MP3 FLV
标准支持的音频即可：
./ffmpeg -i input ac3.mp4 -vcodec copy -acodec aac -f flv output.flv 
```

#### FFmpeg生产关键索引FLV直播使用

```
使用工具yamdi对flv进行转换，然后在flv中的关键帧建立索引
ffmpeg使用add_kryframe_index的方式也可以建立
 ffmpeg -i input.mp4 -c copy -f flv -flvflags add keyframe index output.flv 
```

#### FLV文件格式分析工具

![image-20240302215256604](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302215256604.png)

```
flvparse 工具进行分析
FFrprobe解析：
ffprobe -v trace -i output.flv 

```

### 视频文件转 M3U8

```
Android，ios平台
常见流媒体格式，点播和直播，文件列表存在
```

#### M3U8结构

![image-20240302225427557](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302225427557.png)

```
EXTM3U
M3U8 文件必须包含的标签，并且必须在文件的第一行，所有的 M3U8 文件中必须包含这个标签

EXT-X-VERSION
M3U8 文件的版本，常见的是 ，其实版本已经发展了很多了，直至截稿时，已经发布到了版本 ，经历了这么多版本，期间也对不少标记进行了增删

• EXT-X-TARGETDURATION
个分片都会有一个分片自己的 duration ，这个标签是最大的那个分片的浮点数四五入后的整数值，例如 1.02 四舍五入后的整数为 I, 2.568 四舍五入后的整数为 ，如果M3U8 分片列表中的最大的 duration 的数值为 5.001 ，那么这个 EX X-TARGETDURATION
值为5

EXT-X-MEDIA-SEQUENCE
M3U8 直播时的直播切片序列，，播放对应的序列号的切片 当然关于客户端播放 M3U8 的标准还有更多的讲究，下面就来逐
进行介绍
分片必须是动态改变的，序列不能相同，并且序列必须是增序的
M3U8 列表中没有出现 EXT-X-ENDLIST 标签时，无论这个 M3U8 中有多少
分片，播放分片都是从倒数第3片开始播放，如果不满 片则不应该播放 然，如果有些播放器特别定制了的话，则可以不遵照这个原则
如果前一片分片与后 片分片有不连续的时候播放可能会出错，那么 要使用 EXT-X-DISCONTINUITY 标签来解决这个错误
以播放当前分片的 duration 时间刷新 M3U8 列表，然后做对应的加载动作如果播放列表在刷新之后与之前的列表相同，那么在播放 前分片 duration 半的时间内再刷新

EXTINF
EXTINF是M3U8 列表中每 个分片的 duration ，如上面例子输出信息中的第 个分
片的 duration 4.120000 秒；在 EXTINF 标签中除了 duration 值，还可以包含可选的描
信息，主要为标注切片信息，使用逗号分隔开
EXTINF 下面的信息为具体的分片信息，分片存储路径可以为相对路径，也可以为绝对路径，也可以为互联网的 URL 链接地址


```

##### EXT-X-ENDLIST

```
则表明该 M3U8 文件不会再产生更多的切片，可以理
解为该 M3U8 已停止更新，并且播放分片到这个标签后结束 M3U8 不仅仅是可以作为直播，也可以作为点播存在 ，在 M3U8 文件中保留所有切片信息最后使用 EXT-X-ENDLIST结尾，这个 M3U8 即为点播 M3U8
```

##### EXT-X-STREAM-INF 

```
EXT-X-STREAM-INF 标签出现在 M3U8 中时，主要是出现在多级 M3U8 文件中时，
例如 M3U8 中包含子 M3U8 列表，或者主 M3U8 中包含多码率 M3U8 
参数属性：
BANDWIDTH : BANDWIDTH 的值为最高码率值，当播放 EXT-X-STREAM-INF对应的 M3U8 时占用的最大码率，这个参数是 EX X-STREAM标签中必须要包含的属性

AVERAGE-BANDWIDTH : AVERAGE-BANDWIDTH 的值为平均码率值，当播放TEX -STREAM-INF 下对应的 M3U8 时占用的平均码率，这个参数是 个可选参数

CODECS : CODECS 的值用于声明 EXT-X-STREAM-INF 下面对应 M3U8 里面的音
频编码、 视频编码的信息，例如，若 AAC-LC 的音频与视频为 H.264 Main Profile Level的话，则 CODECS 值为“ mp4a.40.2,avc 1.4d401 ”，这个属性应该出现在 EXT-X-STREAM-INF 标签里，但是并不是所有的 M3U8 中都可以看

ESOLUTION: M3U8 中视频的宽高信息描述，这个属性是个可选属性
FRAME-RATE ：子 M3U8 中的视频帧率，这个属性依然是个可选属性
```

![image-20240302230519610](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302230519610.png)

#### M3U8 结构示例：

```
plaintextCopy Code#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:10
#EXT-X-MEDIA-SEQUENCE:0

#EXTINF:10.010,
media_0.ts
#EXTINF:10.010,
media_1.ts
#EXTINF:10.010,
media_2.ts

#EXT-X-STREAM-INF:BANDWIDTH=800000,RESOLUTION=640x360
low.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=1400000,RESOLUTION=1280x720
mid.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=2800000,RESOLUTION=1920x1080
high.m3u8
```

在这个示例中，除了基本的头部信息和媒体资源链接外，还包含了 EXT-X-STREAM-INF 部分。

#### EXT-X-STREAM-INF 参数使用示例：

- ```
  - #EXT-X-STREAM-INF:BANDWIDTH=800000,RESOLUTION=640x360`：表示一个音视频流，带宽为 800000，分辨率为 640x360，指向了一个名为 low.m3u8 的子播放列表文件。
  - `#EXT-X-STREAM-INF:BANDWIDTH=1400000,RESOLUTION=1280x720`：表示另一个音视频流，带宽为 1400000，分辨率为 1280x720，指向了 mid.m3u8 子播放列表文件。
  - `#EXT-X-STREAM-INF:BANDWIDTH=2800000,RESOLUTION=1920x1080`：表示第三个音视频流，带宽为 2800000，分辨率为 1920x1080，指向了 high.m3u8 子播放列表文件。
  
  通过这种方式，可以为不同清晰度和带宽需求的用户提供合适的音视频流选项。
  
  
  ```

  

### FFmpeg HLS封装 参数

```
FFmpeg 中自带 HLS 的封装参数，使用 HLS 格式即可进行 HLS 的封装，但是生成HLS 的时候有各种参数可以进行参考，例如设置 HLS 列表中切片的前置路径、生成 HLS
TS 切片时设置 TS 的分片参数、生成 HLS 时设置 M3U8 列表中保存的 TS 个数等

常规的从文件转换 HLS 直播时，使用的参数如下：
./ffmpeg -re -i input.mp4 copy -f hls -bsf:v h264_mp4toannexb output.m3u8 

-bsf:v h264_mp4toannexb：将mp4的h.264转为h.264 AnnexB标准的编码，FLV和TS可以直接作为直播传输流的视频“

TS：Transport Stream（传输流）
```

![image-20240302231136579](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240302231136579.png)

```

```

#### start_number 参数

```
/ffmpeg -re -i input.mp4 -c copy -f hls -bsf:v h264_mp4toannexb -start_number
300 output.m3u8
设置第一片的序列数，设置为300，那么将从300.ts开始，可以控制 TS 切片的命名规则和顺序
```

#### hls_time 参数

```
ffmpeg -re -i input.mp4 -c copy -f hls -bsf:v h264 mp4toannexb -hls_time 10 output.m3u8 
用于设置duration，可以控制ts的时间
JIEXTINF:9.920000,
outputl.ts 
好处： 在 HLS 中，通过设置 -hls_time 参数，可以控制每个切片的时长，有利于在不同网络条件下更有效地传输和缓存视频内容
```

#### hls_list_size参数

```
/ffmpeg -re -i input.mp4 -c copy -f hls -bsf:v h264_mp4toannexb -hls_list_size 3 output.m3u8 
控制ts切片的数量，当生成的 TS 切片文件数量超过指定的大小时，FFmpeg 将会删除较旧的切片文件

好处： 避免列表过大导致加载时间过长或占用过多存储空间。提高播放效率和节约存储空间。

```

#### hls_wrap参数（新版舍弃）

```
ffmpeg -re -i input.mp4 -c copy -f hls -bsf:v h264_mp4toannexb -hls_wrap 3 output.m3u8

hls_wrap 参数用于为 M3U8 列表中 TS 设置刷新回滚参数，当 TS 分片序号等于 his_wrap 参数设置的数值时回滚,重新0开始

FFmpeg 中的这个 hls wrap 配直参数对 CDN 存节点的支持并不友好，新版舍弃

```

#### hls_base_url参数

```
/ffmpeg -re -i input.mp4 -c copy -f hls -hls_base_url http://192.168.0.1/live/
- bsf:v h264_mp4toannexb output.m3u8

FFmpeg 中生成 M3U8 时写人的 TS 切片路径默认为与 M3U8 生成的路径相同，但是实际
TS 所存储的路径既可以为本地绝对路径，也可以为当前相对路径，还可以为网络路径，
此使用 his base url 数可以达到该效果，：
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:4
#EXT-X-MEDIA-SEQUENCE:O
#EXTINF:3.760000,
http://192.168.0.1/live/outputO.ts 
```

#### hls_segment_filename 参数

```
./ffmpeg -re -i input.mp4 -c copy -f hls -hls_segment_filename test_output-%d.
ts -bsf:v h264_mp4toannexb output.m3u8
his_ segment_ filename 参数用于为 M3U8 列表设置切片文件名的规则模板参数，如果
his_segment_ filename 参数，那么生成的 TS 切片文件名模板将与 M3U8 的文件名板相同，
上面生产的名字为 test_output-%d.ts

```

#### hls_flags参数

```
/ffmpeg -re -i input.mp4 -c copy -f hls -hls_flags delete_ segments - hls_list_
size 4 -bsf:v h264_mp4toannexb output . m3u8 

正常文件索引，删除过期切片，整数显示duration，列表开始插入discontinuity标签，m3u8不追加endlist

#EXT-X-TARGETDURATION:指定媒体段时长： EXTINF标签中的duration参数用于指定每个媒体段的持续时间，即播放器需要播放该媒体段的时长。
插入EXT-X-DISCONTINUITY标签： 在M3U8播放列表中，当两个相邻的媒体段之间存在不连续性，如编解码器更改、分辨率切换等情况时，需要插入EXT-X-DISCONTINUITY标签来通知播放器进行处理
```

##### delete_segments子参数

```
./ffmpeg -re -i input.mp4 -c copy -f hls -hls_flags delete_ segments - hls_list_size 4 -bsf:v h264_mp4toannexb output . m3u8 

删除已经不在m3u8列表中的旧文件，删除切片是hls_list_size的2倍

```

##### -hls_flags delete_segments`和`-hls_list_size区别

```
区别：

-hls_flags delete_segments参数用于控制是否删除过期的媒体片段文件，确保播放列表中不包含已经无效的内容。
-hls_list_size 4参数用于限制HLS播放列表中媒体片段的最大数量，以控制播放列表的长度和内容。
优点和缺点：

-hls_flags delete_segments参数：

优点：
自动清理：可以自动删除过期的媒体片段文件，节省存储空间并确保播放列表的内容更新。
简化管理：简化了手动管理过期媒体片段的工作，提高了工作效率。
缺点：
可能影响性能：在删除过期媒体片段时，可能会对系统性能产生一定影响。
可能误删：有可能出现误删有效媒体片段的情况，需要谨慎使用。
-hls_list_size 4参数：

优点：
控制列表长度：限制播放列表中媒体片段的数量，有助于管理缓冲和减少加载时间。
提高播放体验：通过控制列表大小，可以提供更流畅的播放体验。
缺点：
可能造成信息丢失：当限制媒体片段数量时，可能会导致一些信息丢失，不利于回溯查找。

```

##### round_durations子参数

```
让durations为整数型

./ffmpeg -re -i input.mp4 -c copy -f hls -hls_flags round durations -bsf:v h264_mp4toannexb output.m3u8
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:4
#EXT-X-MEDIA-SEQUENCE:O
#EXT NF:4,
outputO.ts
#EXTINF:2,
outputl.ts
#EXTINF:2,
output2.ts
#EXTINF:l,
output3.ts
#EXTINF:2,
output4.ts 
```

##### discont_start子参数

```
/ffmpeg -re -i input.mp4 -c copy -f hls -hls_flags discont_start -bsf:v h264_mp4toannexb output.mp4
用于插入ETX_X_DISCONTINUTY,在切片不连续时特别声明

```

##### omit_endlist子参数

```

ffmpeg -re -i input.mp4 -c copy -f hls -hls flags omit endlist -bsf:v h264_mp4toannexb output.m3u8

ffmpeg会在m3u8末尾自动添加EXT_X_ENDLIST标签，omit_endlist不添加EXT_X_ENDLIST标签

存在 EXT-X-ENDLIST：
播放列表结束：播放器会识别到播放列表已经结束，停止加载新的媒体片段，播放完成最后一个片段后结束播放。
静态播放列表：适用于静态内容或已完结的视频流，不再需要更新播放列表。

不存在 EXT-X-ENDLIST：
播放列表持续：播放器会继续解析播放列表，认为还有新的媒体片段会被添加，可以实现动态更新内容。
动态更新：适用于需要动态更新内容的场景，如直播流或需要持续添加新片段的视频流。
```

##### split_by_time子参数

```
ffmpeg -re -i input.ts -c copy -f hls -hls _time 2 -hls_flags split_by_time output.m3u8
his_time 进行切片时不一定预见关键帧，split_by_time会再次进行切片减少ts时间
his_time 参数设置的切片 duration 经生效，效果如下
split_by_time会影响，当视频第一帧不是关键帧，会出现花屏或者首画面显示慢

花屏： 如果分割点处的帧不足以完整还原画面，可能会出现花屏、乱码或者异常显示的情况。
首画面显示慢： 如果分割点之前没有关键帧，播放器可能需要等待直到下一个关键帧出现才能正确显示画面内容，导致首画面显示延迟。
```

#### use_localtime 参数

```
/ffmpeg -re -i input.mp4 -c copy -f hls -use localtime 1 -bsf:v h264_mp4toannexb output.m3u8 
用 use_local_time 参数可以以本地系统时间为切片文件名，
```

#### method 参数

```
ffmpeg -i input.mp4 -c copy -f hls -hls time 3 -hls list size 0 -method PUT -t 30 http://127.0.0.l/test/output_test.m3u8 


method 参数用于设置 HLS M3U8 TS 文件上传至 HTT 务器，使用该功能
的前提是需要有一台 HTTP 服务器，支持上传相关的方法，例如 PUT POST 等，可
尝试使用 Nginx webdav 模块来完成这个功能， method 法的 PUT 方法可用于实现通
TTP 推流 HLS 的功能， 首先需要配置一个支持上传文件的 HTTP 服务器，本例使用
Nginx 来作为 HLS 直播的推流服务器，并且需要支持 WebDAV 功能，
```

### 视频文件切片

```
视频文件切片与 HLS 基本类似，但是 HLS 切片在标准中只支持 TS 格式的切片，并
且是直播与点播切片，既可以使用 segment 方式进行切片，也可以使用 SS 加上 参数进行
切片，下面重点介绍一下 segment SS 加上 参数对视频文件进行剪切的方法

适用于本地存储或传输：用于将大型视频文件分割成多个小块以便于传输或本地存储。
离线播放：可以用于在本地设备上进行离线播放，例如将一个长视频分割成几个部分方便用户观看。
```

#### FFmpeg切片segment参数

![image-20240303211130307](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303211130307.png)![image-20240303211140575](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303211140575.png)

```

```

#### HLS切片和segment_format切片区别

```
通过使用 segment_format 来指定切片文件的格式 ，前面讲述过 HLS 切片的格式主要
MPEGTS 文件格式，那么在 segment 中，可以根据 segment format 来指定切片文件
格式，其既可以为 MPEGTS 切片，也可以为 MP4 切片，还也可以为 FLV 切片等，下面举

```

##### segment_format切片参数

```
./ffmpeg -re -i input.mp4 -c copy -f segment -segment format mp4 test_outputd-%d.mp4

上述命令行表示将一个 MP4 文件切割为 MP4 切片，切出来的切片文件的时间戳与上MP4 的结束时间戳是连续的
从示例中 test-output-O mp4 后的视频时间戳与 test-output-1.mp4 的起始时间戳刚好为一个 duration ，也就 0.040

```

##### segment_list 和segment_Iist_type 参数

```
./ffmpeg -re -i input.mp4 -c copy -f segment -segment_format mp4 -segment_list_
type ffconcat -segment_ list output.1st test_output-%d.mp4
type:
生产ffconcat格式的索引文件名.lst，适用于虚拟轮播场景

FLAT格式的索引文件名.txt，在txt文本中

CSV格式索引文件名.csv,存放在csv文件

m3u8格式索引文件名.m3u8,生成MPEGTS格式文件，存放在csv文件
```

##### reset_timestamps 参数使切片时间戳归。

```
/ffmpeg -re -i input .mp4 -c copy -f segment -segment_format mp4 -reset
timestamps 1 test_outpu －毡 d.mp4
使每一片切片的时间戳归 。可使用 reset timestamps 进行设置
```

##### segment_times 参数

```
/ffmpeg -re -i input.mp4 -c copy -f segment -segment format mp4 -segment times
3,9 ,12 test output-%d.mp4
按照时间点剪切
```

#### FFmpeg使用ss与t参数进行切片

```
ffmpeg -ss 10 -i in.mp4 -c copy out.ts
duration播放器每个片段的时长
从10秒往后切片，遇见关键帧结束

-t参数指定截取的视频长度：
ffmpeg -i in.mp4 -c copy -t 10 -copyts out.mp4
截取mp4前10秒的长度,其次都是start_time =0;

output_ts_offset指定输出的start_time：
ffmpeg -i in.mp4 -c copy -t 10 -output_ts_offset 120 out.mp4
设置duration为10，start_time=120：


```

### 音视频文件音视频流抽取

```
当音视频文件出现异常，分析封装数据，还要进行音视频流部分分析
，如何抽出音视频数据
```

#### FFmpeg 抽取音视频文件中的AAC音频流

```

ffmpeg -i in.mp4 -vn acodec copy out.acc

```

#### FFmpeg 抽取音视频文件中的H.264视频流

```
ffmpeg -i in.mp4 -an vcodec copy out.h264
```

#### FFmpeg 抽取音视频文件中的H.265视频流

```
ffmpeg -i in.mp4 -an vcodec copy-bsf hevc_mp4toannexb -f hevc out.hevc
由于输入文件input.mp4 的容器格式为MP4, MP4 中存储的视频数据并不是标准的
annexb 格式，所以需要将MP4 的视频存储格式存储为annexb格式，输出的HEVC格式
可以直接使用播放器进行观看。
```

#### h.265和h.264详细解释一下区别和优缺点详细

```
H.265（也称为HEVC）和H.264（也称为AVC）是两种常见的视频编解码标准，它们在视频压缩方面有着不同的优缺点。下面是对它们的区别和优缺点的详细解释：

H.265（HEVC）：
优点：
更高的压缩效率：相比H.264，H.265具有更高的压缩效率，可以在相同的画质下以更低的比特率传输视频，或者在相同的比特率下提供更高的画质。
支持更高分辨率：H.265在支持更高分辨率视频（如4K、8K）时表现更出色，能够更好地处理大尺寸视频流。
支持更多的色度：H.265可以提供更广泛的色度范围，使得视频色彩更加丰富和逼真。
缺点：
计算复杂度高：由于H.265采用了更复杂的算法以实现更高的压缩效率，因此编解码过程需要更多的计算资源和时间。
兼容性：一些旧的硬件和软件可能不支持H.265编解码，这可能会导致兼容性问题。
H.264（AVC）：
优点：
更广泛的兼容性：H.264是一种非常成熟的视频编解码标准，得到了广泛的支持和应用，几乎所有的播放器和设备都能够支持H.264编解码。
相对较低的编解码复杂度：相比H.265，H.264的编解码过程相对简单，对于一些资源受限的设备来说更易于实现。
缺点：
较低的压缩效率：相比H.265，H.264在相同画质下需要更高的比特率，因此在传输高质量视频时可能需要更大的带宽。
不擅长处理高分辨率视频：对于4K、8K等高分辨率视频，H.264的压缩效率可能不如H.265。
```

### 音视频操作时系统资源使用情况

```
ffmpeg进行转封装时候cup占用少，因为使用FFmpeg进行封装转换时主要是以读取音视频数据、写入音视频数据为主，并不会
涉及复杂的计算。
/ffmpeg -re -i input.mp4 -c copy -f mpegts output.ts 
如果使用FFmpeg进行编码转换， 则需要进行大量的计算，从而将会占用大量的CPU资源：
ffmpeg -re -i input.mp4 -vcodec libx264 -acodec copy -f mpegts output.ts 
```

## 转码

```
使用 libx264进行H.264 ( AVC）软编码的操作，
H.265 ( HEVC）的编码操作使用的是 libx265

，包括使用MP3、 AAC 的多种参数控制编
码多种质量的音频数据，因为不同的环境使用不同的编码质量能够更好地发挥
FFmpeg 在编解码工作中的作用
```

### FFmpeg 软编码 H.264 与 H.265（三分模块）

```
FFmpeg本身并不支持H.264 的编码器，而是由 FFmpeg 的第三方模块对其进行支持，例如x264和OpenH264， 二者各有
各的优势。
H.264 包括如FLY、 MP4、 HLS (M3U8 ）、 MKV、 TS 等格式；
 支持的像素格式主要包
含yuv420p、 yuvj420p、 yuv422p、 yuvj422p、 yuv444p、 yuvj444p、 nv12、 nv16、 nv21。
```

#### libx264 编码参数简介

![image-20240303221156368](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303221156368.png)

![image-20240303221210734](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303221210734.png)

```
preset 编码器预设参数
```

##### preset参数

```
ultrafast: 最快的编码方式，会牺牲视频质量以换取更快的编码速度。适合对速度要求较高而对视频质量要求较低的场景。

superfast: 比 ultrafast 稍慢一些，保留了一定的视频质量，适合需要稍好一些视频质量但仍然要求较快编码速度的场景。

veryfast: 较快的编码方式，保留了更多的视频质量，并在速度与质量之间做出了平衡。

faster: 比 veryfast 稍慢一些，提供了更好的视频质量，同时在速度和质量之间取得了更好的平衡。

fast: 快速编码方式，提供了更高的视频质量，适合大多数情况下的使用。

medium: 中等速度和质量的平衡预设，适合一般情况下的使用。

slow: 较慢的编码方式，提供了较高的视频质量，适合对视频质量要求较高的场景。

slower: 比 slow 稍慢一些，提供了更高的视频质量。
veryslow: 非常慢的编码方式，提供了最高的视频质量，适合对视频质量要求非常高的场景。
placebo ： 最慢的编码方式
/ffmpeg -i input.mp4 -vcodec libx264 -preset ultrafast -b:v 2000k output.mp4 

```

#####  tune参数

```
 H.264 编码优化参数 tune
 film: 适用于电影内容，通常具有较高的质量要求。该设置将优化视频编码以适应电影类型的内容。

animation: 适用于动画内容，例如卡通、动画片等。这个设置会针对动画内容进行一些优化，以提高压缩效率。

grain: 适用于带有颗粒状噪点的视频内容，可以帮助保留原始视频中的颗粒细节。

stillimage: 适用于静态图像或视频中静止画面占比较大的内容。这个设置可以提高对静态画面的编码效果。

psnr: 优化视频编码以最大化峰值信噪比（PSNR），适合需要精确度量视频质量的场景。

ssim: 优化视频编码以最大化结构相似性指标（SSIM），适合更加符合人眼感知的视频质量优化。

fastdecode: 优化视频编码以便进行快速解码，适合需要低延迟解码的场景。
```

##### profile 与 level 参数

```
ffrnpeg -i input .rnp4 -vcodec libx264 -profile :v baseline -level 3 .1 -s 352x288 -an -y -t 10 output baseline.ts 
ffrnpeg -i input.rnp4 -vcodec libx264 -profile:v high -level 3.1 -s 352x288 -an -y -t 10 output high.ts 
从输出的结果中可以看到， baseline profile 中包含了 0个 B 帧，而high profile 的视频
中包含了 140个B帧。 当进行实时流媒体直播时，采用baseline编码相对main或high 的profile 会更可靠些；但适当地加入B 帧能够有效地降低码率，所以应根据需要与具体的业
务场景进行选择。
```

##### sc threshold参数

```
fmpeg -i input.mp4 -c:v libx264 -g 50 -t 60 output.mp4 
例如从一个画面突然变成另外一个画面时，会强行插入一个关键帧，这时GOP的间隔将会重新开始，
如果将点播文件进行M3U8切片，或者将点播文件进行串流虚拟直播时，可以通过使用sc threshold参数进行设定以决定是否在场景切换时插入关键帧。

ffmpeg -i input.mp4 -c:v libx264 -g 50 -sc_threshold 0 -t 60 -y output.mp4 
控制关键帧方便切片
```

##### x264opts参数

```
fmpeg -i input.mp4 -c:v libx264 -x264opts "bframes=3:b-adapt＝0”－g 50 -sc_ 
threshold 0 output.mp4 
设置I帧、 P帧、 B帧的顺序及规律
视频中的B帧越多，同等码率时的清晰度将会越高，但是B帧越多，编码与解码所带
来的复杂度也就越高，所以合理地使用B帧非常重要，尤其是在进行清晰度与码率衡量时
```

##### nal-hrd参数

```
nal-hrd设为CBR恒定码率。
/ffmpeg -i input.mp4 -c:v libx264 -x264opts "bframes=lO:b-adapt＝。”－b:v
 lOOOk -maxrate lOOOk -minrate lOOOk -bufsize 50k -nal-hrd cbr -g 50 -sc threshold 0 
output.ts 

设置B帧的个数，并且是每两个P帧之间包含 10个B帧
．设置视频码率为 lOOOkbit/s
 ·设置最大码率为 lOOOkbit/s
· 设置最小码率为 1OOOkbit/s 
· 设置编码的buffer大小为 50KB
 · 设置H.264 的编码HRD信号形式为CBR
． 设置每50帧一个GOP
 · 设置场景切换不强行插入关键帧
```

#### VBR、 CBR的编码模式

```
VBR（可变码率）：

在 VBR 模式下，编码器根据视频内容的复杂度自动调整码率，以便更好地保留高质量的视频细节。对于复杂或快速变化的场景，编码器会分配更高的码率以保留细节，而对于静态或简单的场景，编码器会分配较低的码率以减小文件大小。
VBR 适用于内容复杂度变化大的视频，能够在保证视频质量的前提下更高效地利用码率资源，通常能够获得更好的视觉质量。
CBR（恒定码率）：

在 CBR 模式下，编码器会始终以恒定的码率进行压缩，无论视频内容的复杂度如何变化。这意味着无论视频内容是简单还是复杂，输出的视频文件的码率都将保持不变。
CBR 对于需要固定带宽传输或存储的场景非常有用，例如视频直播、视频会议或在线视频流媒体。
```

### FFmpeg 硬编解码

```
CPU编码时的性能也很低，所以出于编码效率及成本考虑，很多时候都会考
虑采用硬编码，常见的硬编码包含Nvidia GPU与Intel QSV两种，
的Nvidia与 Intel硬编码，以及树莓派的
硬编码
```

#### Nvidia GPU 硬编解码

```
FFmpeg集成Nvidia 显卡视频处理模块后，使用FFmpeg能够将Nvidia 的视频编解码功能快速使用起来，下面就来了解一下Nvidia在FFmpeg 中支持的操作参数。
```

### Nvidia 硬编码参数

![image-20240303231154959](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303231154959.png)

![image-20240303231205285](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303231205285.png)

```
FFmpeg 中对于Nvidia 的 GPU编码均支持
哪些参数
h.264编码：可以通过面npeg-h encoder=h264 _ nvenc 进行查看。
支持的像素格式为
yuv420p、 nvl2、 pOlOle、 yuv444p、 严1v444pl6le、 rgbO、 cuda。

h.264解码：可以通过面npeg-h encoder=h264 _ cuvid 进行查看。
支持的像素格式为cuda、
nvl2。
ffmpeg -hwaccel cuvid -vcodec h264_cuvid -i input.mp4 -vf scale_npp=l920:1080 -vcodec h264 nvenc -acodec copy -f mp4 -y output.mp4 
，会将input.mp4 的视频像素改变为 1920× 1080，将码率改变为
2000kbit/s ，输出为 output.mp4。 
```

### Intel QSV 硬编码

![image-20240303231919816](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303231919816.png)

![image-20240303231931064](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303231931064.png)

```
FFmpeg时开启 QSV支持：
./ffmpeg -hide_banner -codecsigrep h264
 Intel QSV H.264 使用举例:
./ffmpeg -i 10M1080P.mp4 -pix_fmt nv12 -vcodec h264_qsv -an -y output.mp4
如上述的输出内容所示， FFmpeg采用的是Intel QSV进行H.264转码，将 1080p/7.8 M 的H.264 的视频转换为 l080p/lM 的视频输出，转码速度近8倍速，如果只使用libx264做软编码时速度并不会有这么快。
```

####  Intel QSV H.265 参数说明

![image-20240303232454019](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303232454019.png)

```
FFmpeg 中的 Intel QSV H.265 ( HEVC）的参数与 Intel QSV H.264 的参数类似，但是FFmpeg 另外还支持指定使用软编码还是硬编码的参数
/ffmpeg -hide_banner -y -hwaccel qsv -i 10Ml080P.mp4 -an -c:v hevc_qsv -load_ plugin hevc_hw -b:v SM -maxrate SM out.mp4 
```

### OS X 系统硬编解码

![image-20240303232631450](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303232631450.png)

```
ffmpeg -vcodec h264_vda -i input.mp4 -vcodec h264_videotoolbox -b:v 2000k 
output.mp4 
```

## FFmpeg 输出 MP3

![image-20240303232757977](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240303232757977.png)

```
同样FFmpeg也可以支持MP3 编码， FFmpeg使用第三方库 libmp3lame 即可编码MP3 格式。 不但如此，
MP3 编码还是低延迟的编码，可以支持的采样率比较多，包含44 100、 48 000、 32 000、
22 050、 24 000、 16 000、 11 025、 12 000、 8000 多种采样率，采样格式也比较多，包含
s32p (signed 32 bits, planar）、 fltp (float, planar）、 s l 6p (signed 16 bits, planar）多种格式，
声道布局方式支持包含mono （单声道模式）、 stereo （环绕立体声模式）
```

#### MP3 的编码质量设置

![image-20240304214643479](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240304214643479.png)

```

ffmpeg -i INPUT -acodec libmp3lame OUTPUT.mp3
在FFmpeg 中进行MP3 编码采用的是第三方库libmp3lame，所以进行MP3 编码时，需要设置编码参数acodec 为 libmp3lame
ffmpeg -i input.mp3 -acodec l ibmp3lame -q:a 8 output.mp3 
使用上图中的转码码率时根据VBR实现的，儿常见的mp3码率都是CBR
```

##### MP3的控制质量

```
，控制质量时需要通过－qscale:a进行控制，也可以使
用表4-9 中的q参数进行控制，质量不同码率也不同
```

#### CBR编码和VBR编码区别优缺点

```
1. CBR（Constant Bit Rate）编码：
恒定比特率： CBR 编码方式会以固定的比特率对音频数据进行压缩，每秒钟产生的比特数保持不变。
固定文件大小： 由于比特率恒定不变，因此使用 CBR 编码方式生成的文件大小相对稳定，不会随着音频内容的复杂度而波动。
适用场景： CBR 编码适用于需要固定比特率的场景，如在线流媒体和广播业务，能够提供稳定的音频质量和文件大小。
2. VBR（Variable Bit Rate）编码：
可变比特率： VBR 编码方式允许根据音频内容的复杂度动态调整比特率，以提高音频质量并尽可能减小文件大小。
优化音质： VBR 在复杂音频段使用更高的比特率，在简单音频段使用较低的比特率，以保证高质量的音频同时尽可能减小文件大小。
适用场景： VBR 编码适用于对音频质量要求较高且希望节省存储空间的场景，如音乐存档和专业音频制作。
3. 区别与应用：
音质和文件大小： CBR 编码方式在保持一致比特率的同时可能牺牲部分音质或增加不必要的文件大小，而 VBR 编码则根据音频内容动态调整比特率，提供更好的音质和更小的文件大小。
应用场景： CBR 适用于需要固定比特率的场景，VBR 则适用于追求更好音质和更小文件大小的场景。
```

#### 平均码率编码参数ABR

```
ffmpeg -i input.mp3 -acodec libmp3lame -b:a 64k -abr 1 output.mp3
ABR参数之后，编码速度将会比VBR高，但是质量会比VBR的编码稍逊一些，比CBR编码好一些，
```

### FFmpeg 输出 AAC

```
无论直播与点播， AAC都是目前最常用的一种音频编码格式，例如
RTMP 直播、 HLS 直播、 RTSP直播、 FLY直播、 FLY点播、 MP4点播等文件中都是常见的AAC音视频
AAC是比mp3高效率高品质，为m4a格式
ffmpeg支持的aac三种编码格式：
aac: FFmpeg 本身的 AAC 编码实现
• libfaac ：第二方的 AAC 编码器
• libfdk aac ：第三方的 AAC 编码器
```

#### FFmpeg 中的 AAC 编码器使用

```
/ffmpeg - i input.mp4 -c:a aac -b:a 160k output.aac 
编码为AAC音频，码率为 160kbit/s，编码生成的输出文
件为output.aac 文件：
ffmpeg -i input.wav -c:a aac -q:a 2 output.m4a 
在编码AAC时，同样也用到了qscale参数，这个q在这里
设置的有效范围为0. 1 ～2之间，其用于设置AAC音频的VBR质量，效果并不可控，
```

#### FDK AAC 第三方的 AAC 编解码 Codec库

```
下libfdk aac的几种编码
```

##### 恒定码率（CBR）模式

```
./ffmpeg -i input.wav -c:a libfdk_aac -b:a 128k output.m4a 
根据这条命令行可以看出， FFmpeg使用libfdk_aac将 input.wav转为恒定码率为
128kbit/s 、 编码为 AAC 的 output.m4a 音频文件
```

##### 动态码率（VBR）模式

![image-20240304220602630](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240304220602630.png)

```
LC: Low Complexity AAC，这种编码相对来说体积比较大，质量稍差
• HE: High-Efficiency AAC，这种编码相对来说体积稍小，质量较好
HEv2: High-Efficiency AAC version 2，这种编码相对来说体积小，质量优
ffmpeg -i input.wav -c:a libfdk_aac -vbr 3 output.m4a 
```

![image-20240304220736533](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240304220736533.png)

#### 高质量 AAC 设置

#####  HE-AAC 音频编码设置

```
ffmpeg -i input.wav -c:a libfdk aac -profile:a aac_he -b:a 64k output.m4a
```

##### HEv2-AAC 音频编码设置

```
ffmpeg -i input.wav -c:a libfdk_aac -profile:a aac_he_v2 -b:a 32k output.m4a 
```

### AAC 音频质量对比

```
AAC-LC 的音频编码可以采用 libfa町、 libfdk_a町、 FFmpeg 内置AAC 三种， 其质量
顺序排列如下。
• libfdk aac 音频编码质量最优
• FFmpeg 内置 AAC 编码次于 libfdk_aac 但优于 libfaac
 • libfaac 在 FFmpeg 内置 AAC 编码为实验品时是除了 libfdk_aac 之外的唯一选择
```

## 系统资源、使用情况

```
音视频转码与音视频转封装的不同之处在于音视频转码会占用大量的计算资源，而转
封装则主要是将音频数据或者视频数据取出，然后转而封装（Mux）成另外一种封装格式，
转封装主要占用IO资源，而转码主要占用CPU资源，同时转码也会使用更多的内存资
源，
ffmepg进行转码：
ffmpeg -re -i input.mp4 -vcodec libx264 -an output.mp4 
```



## FFmpeg 流媒体

```
包括RTMP, HTTP, RTSP 等协议的基本分析,并且配合使用
Wire shark 抓包分析，以加深对 FFmpeg 支持的直播协议的理解
```

## FFmpeg 发布与录制 RTMP流

```
直播是一种常见的技术中，而RTMP直播则是最为常见的一种实时直播，由于RTMP是实时直播,RTMP实时直播的流录制下来
```

### RTMP 参数说明

![image-20240304221611194](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240304221611194.png)

![image-20240304221621858](C:\Users\XL\AppData\Roaming\Typora\typora-user-images\image-20240304221621858.png)

```

```

#### rtmp_app 参数

```
通过使用rtmp_app 参数可以设置RTMP 的推流发布点
ffmpeg -rtmp_app live -i rtmp://publish.chinaffmpeg.com -c copy -f flv output.flv
```

import tkinter as tk
from PIL import Image, ImageTk

class ImageDisplayApp:
    def init(self, master):
        self.master = master
        self.master.title("情感分析结果展示")

    # 设置背景颜色
    self.master.config(bg="#f0f0f0")

    # 添加标题标签
    self.title_label = tk.Label(self.master, text="情感分析结果展示", font=("Helvetica", 24, "bold"), bg="#f0f0f0")
    self.title_label.grid(row=0, column=0, columnspan=2, pady=(20, 10))

    # 创建按钮
    button_font = ("Helvetica", 14)
    button_width = 20
    button_height = 2

    self.show_line_chart_button = tk.Button(self.master, text="情感分析折线图", command=self.show_line_chart, font=button_font, width=button_width, height=button_height)
    self.show_line_chart_button.grid(row=1, column=0, padx=(20, 10), pady=(0, 10))

    self.show_word_cloud_button = tk.Button(self.master, text="情感分析云词图", command=self.show_word_cloud, font=button_font, width=button_width, height=button_height)
    self.show_word_cloud_button.grid(row=2, column=0, padx=(20, 10), pady=10)

    self.show_bar_chart_button = tk.Button(self.master, text="情感分析统计图", command=self.show_bar_chart, font=button_font, width=button_width, height=button_height)
    self.show_bar_chart_button.grid(row=3, column=0, padx=(20, 10), pady=10)

    self.show_emotions_chart_button = tk.Button(self.master, text="情感统计图", command=self.show_emotions_chart, font=button_font, width=button_width, height=button_height)
    self.show_emotions_chart_button.grid(row=4, column=0, padx=(20, 10), pady=10)

    # 创建显示图片的 Label
    self.image_label = tk.Label(self.master, bg="#ffffff")
    self.image_label.grid(row=1, column=1, rowspan=4, padx=(0, 20), pady=10, sticky="nsew")

    # 设置网格布局权重
    self.master.rowconfigure(1, weight=1)
    self.master.columnconfigure(1, weight=1)

def show_line_chart(self):
    self.show_image("E:/xiaopangpang/Weibo-Analyst-master-xiaopang/step3_word_cloud/lineChart.jpg")

def show_word_cloud(self):
    self.show_image("E:/xiaopangpang/Weibo-Analyst-master-xiaopang/step3_word_cloud/wordCloud.png")

def show_bar_chart(self):
    self.show_image("E:/xiaopangpang/Weibo-Analyst-master-xiaopang/step3_word_cloud/barChart.jpg")

def show_emotions_chart(self):
    self.show_image("E:/xiaopangpang/Weibo-Analyst-master-xiaopang/step4_sentiments/emotions_pie_chart.png")

def show_image(self, image_path):
    # 打开图片文件
    try:
        image = Image.open(image_path)
    except IOError:
        print("无法打开图片文件")
        return

    # 调整图片大小以适应 Label
    width, height = image.size
    if width > 2000 or height > 500:
        ratio = min(2000 / width, 500 / height)
        image = image.resize((int(width * ratio), int(height * ratio)), Image.ANTIALIAS)

    # 创建 PhotoImage 对象
    photo = ImageTk.PhotoImage(image)

    # 在 Label 中显示图片
    self.image_label.configure(image=photo)
    self.image_label.image = photo
def main():
    root = tk.Tk()
    app = ImageDisplayApp(root)
    root.mainloop()

if name == "main":
    main()
